{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anggaangoro3/data-science-project/blob/main/scrping_rumah123_selenium%40V1.2.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import threading\n",
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "\n",
        "# --- Pesan Perkenalan ---\n",
        "print(\"Research by @Reza Anggoro\")\n",
        "print(\"Property @scraping V1.2\")\n",
        "print(\"Use it for Educational Purposes only!\")\n",
        "print(\"\\nThis script uses Chromium Browser to crawl data from Rumah123.\")\n",
        "print(\"Note: This script is configured to run on your local device.\")\n",
        "print(\"\\nOpening rumah123 search page...\\n\")\n",
        "print(\"Note: A Stop button window will appear. Click it to stop scraping and save data.\\n\")\n",
        "\n",
        "# --- Pengaturan Opsi Chrome untuk LOCAL (NON-HEADLESS) ---\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"start-maximized\")  # Membuka browser fullscreen\n",
        "#driver.set_page_load_timeout(60)\n",
        "# --- Menambahkan User Agent Acak ---\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
        "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36'\n",
        "]\n",
        "options.add_argument(f'user-agent={random.choice(user_agents)}')\n",
        "\n",
        "# --- Inisialisasi Driver Chrome ---\n",
        "print(\"Starting local Chrome driver...\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "print(\"Driver started successfully.\")\n",
        "\n",
        "# List untuk menyimpan data hasil scrape\n",
        "data_list = []\n",
        "\n",
        "# Path file CSV\n",
        "csv_file = './scraped_land_data.csv'\n",
        "\n",
        "# --- Pengecekan File CSV yang Sudah Ada ---\n",
        "if os.path.exists(csv_file):\n",
        "    old_file = csv_file.replace('.csv', '.old.csv')\n",
        "    try:\n",
        "        os.rename(csv_file, old_file)\n",
        "        print(f\"Found existing file {csv_file}, renaming to {old_file}\")\n",
        "    except OSError as e:\n",
        "        print(f\"Could not rename file {csv_file}. It might be open. Error: {e}\")\n",
        "        print(\"Exiting to prevent data loss.\")\n",
        "        driver.quit()\n",
        "        exit()\n",
        "\n",
        "# URL dasar\n",
        "base_url = \"https://www.rumah123.com/jual/dki-jakarta/tanah/?page=\"\n",
        "\n",
        "# Rentang halaman yang akan di-scrape\n",
        "start_page = 88\n",
        "end_page = 120\n",
        "\n",
        "# Flag untuk stop scraping\n",
        "stop_scraping = False\n",
        "\n",
        "# Fungsi untuk window tombol stop (jalan di thread terpisah)\n",
        "def stop_button_window():\n",
        "    global stop_scraping\n",
        "    root = tk.Tk()\n",
        "    root.title(\"Scraping Control\")\n",
        "    root.geometry(\"200x100\")\n",
        "\n",
        "    def on_stop():\n",
        "        global stop_scraping\n",
        "        stop_scraping = True\n",
        "        messagebox.showinfo(\"Stop\", \"Scraping will stop after current operation.\")\n",
        "        root.destroy()\n",
        "\n",
        "    button = tk.Button(root, text=\"Stop Scraping\", command=on_stop)\n",
        "    button.pack(pady=20)\n",
        "    root.mainloop()\n",
        "\n",
        "# Jalankan window stop di thread background\n",
        "threading.Thread(target=stop_button_window, daemon=True).start()\n",
        "\n",
        "# --- Loop Halaman Utama (PAGINATION) ---\n",
        "for page in range(start_page, end_page + 1):\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    url = base_url + str(page)\n",
        "    print(f\"Opening page {page}: {url}\")\n",
        "    driver.get(url)\n",
        "\n",
        "    # Jeda acak untuk memuat halaman\n",
        "    time.sleep(random.uniform(3, 5))\n",
        "\n",
        "    # --- Pengecekan CAPTCHA yang Terlihat ---\n",
        "    captcha_detected = False\n",
        "    try:\n",
        "        captcha_element = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "        if captcha_element.is_displayed():\n",
        "            captcha_detected = True\n",
        "    except NoSuchElementException:\n",
        "        pass\n",
        "\n",
        "    if captcha_detected:\n",
        "        print(f\"!!! CAPTCHA DETECTED on page {page}. !!!\")\n",
        "        print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\n",
        "        print(\"!!! Skrip akan menjeda selama 25 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "        time.sleep(25)\n",
        "        print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "    # --- Blok untuk Scrolling ---\n",
        "    print(\"Waiting for page layout to settle before scrolling...\")\n",
        "    time.sleep(1.5)\n",
        "\n",
        "    total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    current_scroll = 0\n",
        "    scroll_count = 1\n",
        "    max_scroll_attempts = 50\n",
        "    print(\"Starting scroll (slower and deeper)...\")\n",
        "\n",
        "    while current_scroll < total_height and scroll_count < max_scroll_attempts:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        scroll_amount = random.randint(400, 700)\n",
        "        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
        "\n",
        "        print(f\"-- Scrolling... ({scroll_count}), waiting for content...\")\n",
        "        time.sleep(random.uniform(1.5, 2.2))\n",
        "\n",
        "        current_scroll += scroll_amount\n",
        "        scroll_count += 1\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "        if new_height == total_height:\n",
        "            print(\"-- Page height not changing, likely at bottom.\")\n",
        "            break\n",
        "        total_height = new_height\n",
        "\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    print(\"Doing one final scroll to the absolute bottom...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "    print(\"Waiting 3 seconds at the bottom for final loads...\")\n",
        "    time.sleep(3.0)\n",
        "\n",
        "    print(\"Experiment: Scrolling back to top slowly...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
        "    time.sleep(random.uniform(1.5, 2.5))\n",
        "\n",
        "    mid_height = total_height // 2\n",
        "    print(f\"Experiment: Scrolling to middle ({mid_height}px) and pausing...\")\n",
        "    driver.execute_script(f\"window.scrollTo(0, {mid_height});\")\n",
        "    time.sleep(random.uniform(2.0, 3.0))\n",
        "\n",
        "    print(\"Scrolling finished for this page.\")\n",
        "\n",
        "    # --- Ambil semua link (href) dari halaman daftar ---\n",
        "    href_list = []\n",
        "    try:\n",
        "        listings = driver.find_elements(By.CSS_SELECTOR, \"a.gap-1.w-full\")\n",
        "        for listing in listings:\n",
        "            try:\n",
        "                href = listing.get_attribute('href')\n",
        "                if href and href.startswith('https://www.rumah123.com/properti/'):\n",
        "                    href_list.append(href)\n",
        "            except:\n",
        "                pass\n",
        "        href_list = list(dict.fromkeys(href_list))\n",
        "        print(f\"Found {len(href_list)} property links on page {page}.\")\n",
        "    except NoSuchElementException:\n",
        "        print(f\"No more listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    if not href_list:\n",
        "        print(f\"No valid listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    # --- Loop Halaman Detail (per link) ---\n",
        "    for href in href_list:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Opening detail page: {href}\")\n",
        "\n",
        "        try:\n",
        "            # Coba buka halaman\n",
        "            driver.get(href)\n",
        "\n",
        "        except TimeoutException:\n",
        "            # Jika halaman gagal dimuat dalam 60 detik\n",
        "            print(f\"!!! PAGE TIMEOUT: Halaman {href} terlalu lama dimuat. Melewati...\")\n",
        "            # 'continue' akan mengabaikan sisa kode di loop ini\n",
        "            # dan langsung lanjut ke 'href' berikutnya\n",
        "            continue\n",
        "\n",
        "        except Exception as e:\n",
        "            # Menangkap error lain jika terjadi\n",
        "            print(f\"!!! ERROR LAIN saat membuka {href}: {e}. Melewati...\")\n",
        "            continue\n",
        "\n",
        "        # Kode ini hanya akan berjalan JIKA 'driver.get()' BERHASIL\n",
        "        time.sleep(random.uniform(3, 6))\n",
        "        # ... (sisa kode Anda untuk cek CAPTCHA dan extract data) ...\n",
        "        # Cek VISIBLE CAPTCHA di halaman detail\n",
        "        captcha_detected = False\n",
        "        try:\n",
        "            captcha_element_detail = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "            if captcha_element_detail.is_displayed():\n",
        "                captcha_detected = True\n",
        "        except NoSuchElementException:\n",
        "            pass\n",
        "\n",
        "        if captcha_detected:\n",
        "            print(f\"!!! CAPTCHA DETECTED on detail page {href}. !!!\")\n",
        "            print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "            time.sleep(20)\n",
        "            print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "        # Tambahkan scroll sedikit pada page detail (2-3 kali)\n",
        "        detail_scroll_count = random.randint(2, 3)\n",
        "        for i in range(detail_scroll_count):\n",
        "            scroll_amount = random.randint(200, 400)\n",
        "            driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
        "            time.sleep(random.uniform(0.5, 1.0))\n",
        "\n",
        "        # Tambahkan waktu sedikit untuk memastikan seluruh nilai muncul\n",
        "        time.sleep(random.uniform(2, 3))\n",
        "\n",
        "        # Coba klik tombol \"Muat lebih banyak\" (jika ada)\n",
        "        expand_clicked = False\n",
        "        try:\n",
        "            expand_container = driver.find_element(By.CSS_SELECTOR, \"#property-information > div:nth-of-type(1) > div:nth-of-type(2)\")\n",
        "            expand_button = expand_container.find_element(By.CSS_SELECTOR, \"span[data-test-id='expanded-specification']\")\n",
        "            ActionChains(driver).move_to_element(expand_button).perform()\n",
        "            time.sleep(random.uniform(0.5, 1))\n",
        "            expand_button.click()\n",
        "            time.sleep(random.uniform(1, 2))\n",
        "            print(\"Successfully clicked 'Muat lebih banyak' button.\")\n",
        "            expand_clicked = True\n",
        "        except Exception as e:\n",
        "            print(f\"No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\")\n",
        "\n",
        "        # --- Blok Ekstraksi Data (DIPERBAIKI: Tambah try-except lengkap) ---\n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        while retry_count < max_retries:\n",
        "            data = {}\n",
        "            try:\n",
        "                data['Product_sku_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(4) p.text-sm\").text\n",
        "            except:\n",
        "                data['Product_sku_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Place_name_0'] = driver.find_element(By.TAG_NAME, \"h1\").text\n",
        "            except:\n",
        "                data['Place_name_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Total_Price_0'] = driver.find_element(By.CSS_SELECTOR, \"span.text-primary\").text\n",
        "            except:\n",
        "                data['Total_Price_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Price_per_meter_0'] = driver.find_element(By.CSS_SELECTOR, \"span.font-normal.text-sm\").text\n",
        "            except:\n",
        "                data['Price_per_meter_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Land_Area_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex-col:nth-of-type(1) p.text-gray-800\").text\n",
        "            except:\n",
        "                data['Land_Area_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Certificate_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.text-base\").text\n",
        "            except:\n",
        "                data['Certificate_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Land_Dimensions_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(1) p.font-medium.text-sm\").text\n",
        "            except:\n",
        "                data['Land_Dimensions_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Property_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.font-medium.text-sm\").text\n",
        "            except:\n",
        "                data['Property_Type_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Ad_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.items-center:nth-of-type(3) p.text-sm\").text\n",
        "            except:\n",
        "                data['Ad_Type_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Place_PostalAddress_addressLocality_0'] = driver.find_element(By.CSS_SELECTOR, \"p.mb-2\").text\n",
        "            except:\n",
        "                data['Place_PostalAddress_addressLocality_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['BreadcrumbList_ListItem_name_2'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(4) a\").text\n",
        "            except:\n",
        "                data['BreadcrumbList_ListItem_name_2'] = ''\n",
        "\n",
        "            try:\n",
        "                data['BreadcrumbList_ListItem_name_3'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(5) a\").text\n",
        "            except:\n",
        "                data['BreadcrumbList_ListItem_name_3'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Product_description_0'] = driver.find_element(By.CSS_SELECTOR, \"p.font-light.text-sm\").text\n",
        "            except:\n",
        "                data['Product_description_0'] = ''\n",
        "\n",
        "            # Peningkatan 1: Cek jika CAPTCHA terdeteksi berdasarkan 'Place_name_0'\n",
        "            if data['Place_name_0'] == 'www.rumah123.com':\n",
        "                print(f\"!!! CAPTCHA DETECTED via data check on detail page {href}. !!!\")\n",
        "                print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\n",
        "                print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "                time.sleep(20)\n",
        "                print(\"Waktu jeda selesai, reloading detail page...\")\n",
        "                driver.get(href)\n",
        "                time.sleep(random.uniform(3, 6))\n",
        "                retry_count += 1\n",
        "                continue  # Ekstrak ulang\n",
        "            else:\n",
        "                break  # Sukses, lanjut\n",
        "\n",
        "        if retry_count == max_retries:\n",
        "            print(f\"Max retries reached for {href}. Proceeding with possibly incomplete data.\")\n",
        "\n",
        "        # Peningkatan 2: Koreksi inkonsistensi jika expand gagal\n",
        "        if not expand_clicked:\n",
        "            # Shift values based on observed mismatch\n",
        "            temp_sku = data['Ad_Type_0']\n",
        "            temp_ad_type = data['Property_Type_0']\n",
        "            temp_property_type = data['Land_Dimensions_0']\n",
        "            # Assume Land_Dimensions not available or parse from description if needed\n",
        "            data['Product_sku_0'] = temp_sku\n",
        "            data['Ad_Type_0'] = temp_ad_type\n",
        "            data['Property_Type_0'] = temp_property_type\n",
        "            data['Land_Dimensions_0'] = ''  # Or extract from description if possible\n",
        "\n",
        "        # Print data untuk debug\n",
        "        print(f\"Extracted data: {data}\")\n",
        "\n",
        "        data_list.append(data)\n",
        "\n",
        "        # Simpan data ke CSV secara bertahap\n",
        "        df = pd.DataFrame(data_list)\n",
        "        df.to_csv(csv_file, index=False)\n",
        "        print(f\"Your data saved to: {csv_file}\")\n",
        "        print(f\"Total items saved: {len(data_list)}\\n\")\n",
        "\n",
        "        # Jeda sebelum kembali ke halaman daftar\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Going back to listing page {page}...\")\n",
        "        driver.get(url)\n",
        "        time.sleep(random.uniform(2, 4))\n",
        "\n",
        "    # Jeda antar halaman\n",
        "    print(f\"--Finished page {page}. Taking a break, waiting for 10 seconds...\\n\")\n",
        "    time.sleep(10)\n",
        "\n",
        "# --- Selesai ---\n",
        "driver.quit()\n",
        "\n",
        "# Simpan data terakhir jika belum\n",
        "if data_list:\n",
        "    df = pd.DataFrame(data_list)\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"Final data saved to: {csv_file}\")\n",
        "    print(f\"Total items saved: {len(data_list)}\")\n",
        "\n",
        "print(\"Scraping completed (or stopped). Data saved to 'scraped_land_data.csv'.\")"
      ],
      "metadata": {
        "id": "O8CKtNDxdI7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "f9d5b34c",
        "outputId": "3d95d1c4-2d12-4b06-9669-5c6d4e07f983"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_scraped_data(filename='scraped_land_data.csv'):\n",
        "    \"\"\"Reads scraped data from a CSV file into a pandas DataFrame.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filename)\n",
        "        print(f\"Successfully loaded data from '{filename}'.\")\n",
        "        print(f\"DataFrame shape: {df.shape}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filename}' not found.\")\n",
        "        return None\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"Warning: The file '{filename}' is empty or only contains headers.\")\n",
        "        return pd.DataFrame() # Return an empty DataFrame\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "        return None\n",
        "\n",
        "scraped_df = read_scraped_data()\n",
        "\n",
        "if scraped_df is not None and not scraped_df.empty:\n",
        "    print(\"Displaying the entire scraped dataset:\")\n",
        "    display(scraped_df)\n",
        "elif scraped_df is not None and scraped_df.empty:\n",
        "    print(\"The dataset is empty. No data to display.\")\n",
        "else:\n",
        "    print(\"Could not read the dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from 'scraped_land_data.csv'.\n",
            "DataFrame shape: (2, 13)\n",
            "Displaying the entire scraped dataset:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Product_sku_0                                       Place_name_0  \\\n",
              "0        Dijual  Rumah Hitung Tanah Area Komersial di Jalan Jak...   \n",
              "1    las8777362  Tanah kavling di pondok indah, prime location ...   \n",
              "\n",
              "          Total_Price_0  Price_per_meter_0      Land_Area_0 Certificate_0  \\\n",
              "0  Rp 22,5 Miliar Total                NaN  529 m² (28x20m)           SHM   \n",
              "1  Rp 18,8 Miliar Total                NaN  448 m² (24x19m)           SHM   \n",
              "\n",
              "  Land_Dimensions_0 Property_Type_0 Ad_Type_0  \\\n",
              "0           28x20 m             Ada     Tanah   \n",
              "1           24x19 m           Tanah    Dijual   \n",
              "\n",
              "  Place_PostalAddress_addressLocality_0 BreadcrumbList_ListItem_name_2  \\\n",
              "0                Menteng, Jakarta Pusat                  Jakarta Pusat   \n",
              "1         Pondok Indah, Jakarta Selatan                Jakarta Selatan   \n",
              "\n",
              "  BreadcrumbList_ListItem_name_3  \\\n",
              "0                        Menteng   \n",
              "1                   Pondok Indah   \n",
              "\n",
              "                               Product_description_0  \n",
              "0  Rumah Hitung Tanah area komersial \\ndi Jalan J...  \n",
              "1  Tanah kavling, \\nPrime location di Pondok Inda...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product_sku_0</th>\n",
              "      <th>Place_name_0</th>\n",
              "      <th>Total_Price_0</th>\n",
              "      <th>Price_per_meter_0</th>\n",
              "      <th>Land_Area_0</th>\n",
              "      <th>Certificate_0</th>\n",
              "      <th>Land_Dimensions_0</th>\n",
              "      <th>Property_Type_0</th>\n",
              "      <th>Ad_Type_0</th>\n",
              "      <th>Place_PostalAddress_addressLocality_0</th>\n",
              "      <th>BreadcrumbList_ListItem_name_2</th>\n",
              "      <th>BreadcrumbList_ListItem_name_3</th>\n",
              "      <th>Product_description_0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dijual</td>\n",
              "      <td>Rumah Hitung Tanah Area Komersial di Jalan Jak...</td>\n",
              "      <td>Rp 22,5 Miliar Total</td>\n",
              "      <td>NaN</td>\n",
              "      <td>529 m² (28x20m)</td>\n",
              "      <td>SHM</td>\n",
              "      <td>28x20 m</td>\n",
              "      <td>Ada</td>\n",
              "      <td>Tanah</td>\n",
              "      <td>Menteng, Jakarta Pusat</td>\n",
              "      <td>Jakarta Pusat</td>\n",
              "      <td>Menteng</td>\n",
              "      <td>Rumah Hitung Tanah area komersial \\ndi Jalan J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>las8777362</td>\n",
              "      <td>Tanah kavling di pondok indah, prime location ...</td>\n",
              "      <td>Rp 18,8 Miliar Total</td>\n",
              "      <td>NaN</td>\n",
              "      <td>448 m² (24x19m)</td>\n",
              "      <td>SHM</td>\n",
              "      <td>24x19 m</td>\n",
              "      <td>Tanah</td>\n",
              "      <td>Dijual</td>\n",
              "      <td>Pondok Indah, Jakarta Selatan</td>\n",
              "      <td>Jakarta Selatan</td>\n",
              "      <td>Pondok Indah</td>\n",
              "      <td>Tanah kavling, \\nPrime location di Pondok Inda...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (kode script Anda sebelumnya)\n",
        "\"\"\"\n",
        "# --- Selesai ---\n",
        "driver.quit()\n",
        "\n",
        "# Simpan data terakhir jika belum\n",
        "if data_list:\n",
        "    df = pd.DataFrame(data_list)\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"Final data saved to: {csv_file}\")\n",
        "    print(f\"Total items saved: {len(data_list)}\")\n",
        "\"\"\"\n",
        "# Tambahkan ini untuk hibernate otomatis (Windows)\n",
        "import os\n",
        "print(\"Scraping selesai. Memulai hibernate laptop...\")\n",
        "os.system(\"shutdown /h\")  # Perintah hibernate di Windows\n",
        "\n",
        "print(\"Scraping completed (or stopped). Data saved to 'scraped_land_data.csv'.\")"
      ],
      "metadata": {
        "id": "z80n69jDtWu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac65e600-84db-4183-cff8-8a19ba77f985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping selesai. Memulai hibernate laptop...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import threading\n",
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "\n",
        "# --- Pesan Perkenalan ---\n",
        "print(\"Research by @Reza Anggoro\")\n",
        "print(\"Property @scraping V1.3\")\n",
        "print(\"Use it for Educational Purposes only!\")\n",
        "print(\"\\nThis script uses Chromium Browser to crawl data from Rumah123.\")\n",
        "print(\"Note: This script is configured to run on your local device.\")\n",
        "print(\"\\nOpening rumah123 search page...\\n\")\n",
        "print(\"Note: A Stop button window will appear. Click it to stop scraping and save data.\\n\")\n",
        "\n",
        "# --- Pengaturan Opsi Chrome untuk LOCAL (NON-HEADLESS) ---\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"start-maximized\")  # Membuka browser fullscreen\n",
        "#driver.set_page_load_timeout(60)\n",
        "# --- Menambahkan User Agent Acak ---\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
        "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36'\n",
        "]\n",
        "options.add_argument(f'user-agent={random.choice(user_agents)}')\n",
        "\n",
        "# --- Inisialisasi Driver Chrome ---\n",
        "print(\"Starting local Chrome driver...\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "print(\"Driver started successfully.\")\n",
        "\n",
        "# List untuk menyimpan data hasil scrape\n",
        "data_list = []\n",
        "\n",
        "# Path file CSV\n",
        "csv_file = './scraped_land_data.csv'\n",
        "\n",
        "# --- Pengecekan File CSV yang Sudah Ada ---\n",
        "if os.path.exists(csv_file):\n",
        "    old_file = csv_file.replace('.csv', '.old.csv')\n",
        "    try:\n",
        "        os.rename(csv_file, old_file)\n",
        "        print(f\"Found existing file {csv_file}, renaming to {old_file}\")\n",
        "    except OSError as e:\n",
        "        print(f\"Could not rename file {csv_file}. It might be open. Error: {e}\")\n",
        "        print(\"Exiting to prevent data loss.\")\n",
        "        driver.quit()\n",
        "        exit()\n",
        "\n",
        "# URL dasar\n",
        "base_url = \"https://www.rumah123.com/jual/dki-jakarta/tanah/?page=\"\n",
        "\n",
        "# Rentang halaman yang akan di-scrape\n",
        "start_page = 104\n",
        "end_page = 750\n",
        "\n",
        "# Flag untuk stop scraping\n",
        "stop_scraping = False\n",
        "\n",
        "# Fungsi untuk window tombol stop (jalan di thread terpisah)\n",
        "def stop_button_window():\n",
        "    global stop_scraping\n",
        "    root = tk.Tk()\n",
        "    root.title(\"Scraping Control\")\n",
        "    root.geometry(\"200x100\")\n",
        "\n",
        "    def on_stop():\n",
        "        global stop_scraping\n",
        "        stop_scraping = True\n",
        "        messagebox.showinfo(\"Stop\", \"Scraping will stop after current operation.\")\n",
        "        root.destroy()\n",
        "\n",
        "    button = tk.Button(root, text=\"Stop Scraping\", command=on_stop)\n",
        "    button.pack(pady=20)\n",
        "    root.mainloop()\n",
        "\n",
        "# Jalankan window stop di thread background\n",
        "threading.Thread(target=stop_button_window, daemon=True).start()\n",
        "\n",
        "# --- Loop Halaman Utama (PAGINATION) ---\n",
        "for page in range(start_page, end_page + 1):\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    url = base_url + str(page)\n",
        "    print(f\"Opening page {page}: {url}\")\n",
        "    driver.get(url)\n",
        "\n",
        "    # Jeda acak untuk memuat halaman\n",
        "    time.sleep(random.uniform(5, 7))\n",
        "\n",
        "    # --- Pengecekan CAPTCHA yang Terlihat ---\n",
        "    captcha_detected = False\n",
        "    try:\n",
        "        captcha_element = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "        if captcha_element.is_displayed():\n",
        "            captcha_detected = True\n",
        "    except NoSuchElementException:\n",
        "        pass\n",
        "\n",
        "    if captcha_detected:\n",
        "        print(f\"!!! CAPTCHA DETECTED on page {page}. !!!\")\n",
        "        print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\n",
        "        print(\"!!! Skrip akan menjeda selama 25 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "        time.sleep(25)\n",
        "        print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "    # --- Blok untuk Scrolling ---\n",
        "    print(\"Waiting for page layout to settle before scrolling...\")\n",
        "    time.sleep(1.5)\n",
        "\n",
        "    total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    current_scroll = 0\n",
        "    scroll_count = 1\n",
        "    max_scroll_attempts = 50\n",
        "    print(\"Starting scroll (slower and deeper)...\")\n",
        "\n",
        "    while current_scroll < total_height and scroll_count < max_scroll_attempts:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        scroll_amount = random.randint(400, 700)\n",
        "        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
        "\n",
        "        print(f\"-- Scrolling... ({scroll_count}), waiting for content...\")\n",
        "        time.sleep(random.uniform(1.5, 2.2))\n",
        "\n",
        "        current_scroll += scroll_amount\n",
        "        scroll_count += 1\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "        if new_height == total_height:\n",
        "            print(\"-- Page height not changing, likely at bottom.\")\n",
        "            break\n",
        "        total_height = new_height\n",
        "\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    print(\"Doing one final scroll to the absolute bottom...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "    print(\"Waiting 3 seconds at the bottom for final loads...\")\n",
        "    time.sleep(3.0)\n",
        "\n",
        "    print(\"Experiment: Scrolling back to top slowly...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
        "    time.sleep(random.uniform(1.5, 2.5))\n",
        "\n",
        "    mid_height = total_height // 2\n",
        "    print(f\"Experiment: Scrolling to middle ({mid_height}px) and pausing...\")\n",
        "    driver.execute_script(f\"window.scrollTo(0, {mid_height});\")\n",
        "    time.sleep(random.uniform(2.0, 3.0))\n",
        "\n",
        "    print(\"Scrolling finished for this page.\")\n",
        "\n",
        "    # --- Ambil semua link (href) dari halaman daftar ---\n",
        "    href_list = []\n",
        "    try:\n",
        "        listings = driver.find_elements(By.CSS_SELECTOR, \"a.gap-1.w-full\")\n",
        "        for listing in listings:\n",
        "            try:\n",
        "                href = listing.get_attribute('href')\n",
        "                if href and href.startswith('https://www.rumah123.com/properti/'):\n",
        "                    href_list.append(href)\n",
        "            except:\n",
        "                pass\n",
        "        href_list = list(dict.fromkeys(href_list))\n",
        "        print(f\"Found {len(href_list)} property links on page {page}.\")\n",
        "    except NoSuchElementException:\n",
        "        print(f\"No more listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    if not href_list:\n",
        "        print(f\"No valid listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    # --- Loop Halaman Detail (per link) ---\n",
        "    for href in href_list:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Opening detail page: {href}\")\n",
        "\n",
        "        try:\n",
        "            # Coba buka halaman\n",
        "            driver.get(href)\n",
        "\n",
        "        except TimeoutException:\n",
        "            # Jika halaman gagal dimuat dalam 60 detik\n",
        "            print(f\"!!! PAGE TIMEOUT: Halaman {href} terlalu lama dimuat. Melewati...\")\n",
        "            # 'continue' akan mengabaikan sisa kode di loop ini\n",
        "            # dan langsung lanjut ke 'href' berikutnya\n",
        "            continue\n",
        "\n",
        "        except Exception as e:\n",
        "            # Menangkap error lain jika terjadi\n",
        "            print(f\"!!! ERROR LAIN saat membuka {href}: {e}. Melewati...\")\n",
        "            continue\n",
        "\n",
        "        # Kode ini hanya akan berjalan JIKA 'driver.get()' BERHASIL\n",
        "        time.sleep(random.uniform(3, 6))\n",
        "        # ... (sisa kode Anda untuk cek CAPTCHA dan extract data) ...\n",
        "        # Cek VISIBLE CAPTCHA di halaman detail\n",
        "        captcha_detected = False\n",
        "        try:\n",
        "            captcha_element_detail = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "            if captcha_element_detail.is_displayed():\n",
        "                captcha_detected = True\n",
        "        except NoSuchElementException:\n",
        "            pass\n",
        "\n",
        "        if captcha_detected:\n",
        "            print(f\"!!! CAPTCHA DETECTED on detail page {href}. !!!\")\n",
        "            print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "            time.sleep(20)\n",
        "            print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "        # Tambahkan scroll sedikit pada page detail (2-3 kali)\n",
        "        detail_scroll_count = random.randint(1, 2)\n",
        "        for i in range(detail_scroll_count):\n",
        "            scroll_amount = random.randint(200, 400)\n",
        "            driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
        "            time.sleep(random.uniform(0.5, 1.0))\n",
        "\n",
        "        # Tambahkan waktu sedikit untuk memastikan seluruh nilai muncul\n",
        "        time.sleep(random.uniform(2, 3))\n",
        "\n",
        "        # Coba klik tombol \"Muat lebih banyak\" (jika ada)\n",
        "        expand_clicked = False\n",
        "        try:\n",
        "            expand_container = driver.find_element(By.CSS_SELECTOR, \"#property-information > div:nth-of-type(1) > div:nth-of-type(2)\")\n",
        "            expand_button = expand_container.find_element(By.CSS_SELECTOR, \"span[data-test-id='expanded-specification']\")\n",
        "            ActionChains(driver).move_to_element(expand_button).perform()\n",
        "            time.sleep(random.uniform(0.5, 1))\n",
        "            expand_button.click()\n",
        "            time.sleep(random.uniform(1, 2))\n",
        "            print(\"Successfully clicked 'Muat lebih banyak' button.\")\n",
        "            expand_clicked = True\n",
        "        except Exception as e:\n",
        "            print(f\"No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\")\n",
        "\n",
        "        # --- Blok Ekstraksi Data (DIPERBAIKI: Tambah try-except lengkap) ---\n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        while retry_count < max_retries:\n",
        "            data = {}\n",
        "            try:\n",
        "                data['Product_sku_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(4) p.text-sm\").text\n",
        "            except:\n",
        "                data['Product_sku_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Place_name_0'] = driver.find_element(By.TAG_NAME, \"h1\").text\n",
        "            except:\n",
        "                data['Place_name_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Total_Price_0'] = driver.find_element(By.CSS_SELECTOR, \"span.text-primary\").text\n",
        "            except:\n",
        "                data['Total_Price_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Price_per_meter_0'] = driver.find_element(By.CSS_SELECTOR, \"span.font-normal.text-sm\").text\n",
        "            except:\n",
        "                data['Price_per_meter_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Land_Area_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex-col:nth-of-type(1) p.text-gray-800\").text\n",
        "            except:\n",
        "                data['Land_Area_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Certificate_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.text-base\").text\n",
        "            except:\n",
        "                data['Certificate_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Land_Dimensions_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(1) p.font-medium.text-sm\").text\n",
        "            except:\n",
        "                data['Land_Dimensions_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Property_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.font-medium.text-sm\").text\n",
        "            except:\n",
        "                data['Property_Type_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Ad_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.items-center:nth-of-type(3) p.text-sm\").text\n",
        "            except:\n",
        "                data['Ad_Type_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Place_PostalAddress_addressLocality_0'] = driver.find_element(By.CSS_SELECTOR, \"p.mb-2\").text\n",
        "            except:\n",
        "                data['Place_PostalAddress_addressLocality_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['BreadcrumbList_ListItem_name_2'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(4) a\").text\n",
        "            except:\n",
        "                data['BreadcrumbList_ListItem_name_2'] = ''\n",
        "\n",
        "            try:\n",
        "                data['BreadcrumbList_ListItem_name_3'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(5) a\").text\n",
        "            except:\n",
        "                data['BreadcrumbList_ListItem_name_3'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Product_description_0'] = driver.find_element(By.CSS_SELECTOR, \"p.font-light.text-sm\").text\n",
        "            except:\n",
        "                data['Product_description_0'] = ''\n",
        "\n",
        "            # Peningkatan 1: Cek jika CAPTCHA terdeteksi berdasarkan 'Place_name_0'\n",
        "            if data['Place_name_0'] == 'www.rumah123.com':\n",
        "                print(f\"!!! CAPTCHA DETECTED via data check on detail page {href}. !!!\")\n",
        "                print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\n",
        "                print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "                time.sleep(20)\n",
        "                print(\"Waktu jeda selesai, reloading detail page...\")\n",
        "                driver.get(href)\n",
        "                time.sleep(random.uniform(3, 6))\n",
        "                retry_count += 1\n",
        "                continue  # Ekstrak ulang\n",
        "            else:\n",
        "                break  # Sukses, lanjut\n",
        "\n",
        "        if retry_count == max_retries:\n",
        "            print(f\"Max retries reached for {href}. Proceeding with possibly incomplete data.\")\n",
        "\n",
        "        # Peningkatan 2: Koreksi inkonsistensi jika expand gagal\n",
        "        if not expand_clicked:\n",
        "            # Shift values based on observed mismatch\n",
        "            temp_sku = data['Ad_Type_0']\n",
        "            temp_ad_type = data['Property_Type_0']\n",
        "            temp_property_type = data['Land_Dimensions_0']\n",
        "            # Assume Land_Dimensions not available or parse from description if needed\n",
        "            data['Product_sku_0'] = temp_sku\n",
        "            data['Ad_Type_0'] = temp_ad_type\n",
        "            data['Property_Type_0'] = temp_property_type\n",
        "            data['Land_Dimensions_0'] = ''  # Or extract from description if possible\n",
        "\n",
        "        # Print data untuk debug\n",
        "        print(f\"Extracted data: {data}\")\n",
        "\n",
        "        data_list.append(data)\n",
        "\n",
        "        # Simpan data ke CSV secara bertahap\n",
        "        df = pd.DataFrame(data_list)\n",
        "        df.to_csv(csv_file, index=False)\n",
        "        print(f\"Your data saved to: {csv_file}\")\n",
        "        print(f\"Total items saved: {len(data_list)}\\n\")\n",
        "\n",
        "        # Jeda sebelum kembali ke halaman daftar\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Going back to listing page {page}...\")\n",
        "        driver.get(url)\n",
        "        time.sleep(random.uniform(2, 4))\n",
        "\n",
        "    # Jeda antar halaman\n",
        "    print(f\"--Finished page {page}. Taking a break, waiting for 10 seconds...\\n\")\n",
        "    time.sleep(10)\n",
        "\n",
        "# --- Selesai ---\n",
        "driver.quit()\n",
        "\n",
        "# Simpan data terakhir jika belum\n",
        "if data_list:\n",
        "    df = pd.DataFrame(data_list)\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"Final data saved to: {csv_file}\")\n",
        "    print(f\"Total items saved: {len(data_list)}\")\n",
        "\n",
        "print(\"Scraping completed (or stopped). Data saved to 'scraped_land_data.csv'.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uBnAz0trLVCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45616a26-e50d-4377-aa31-b8170387e7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research by @Reza Anggoro\n",
            "Property @scraping V1.2\n",
            "Use it for Educational Purposes only!\n",
            "\n",
            "This script uses Chromium Browser to crawl data from Rumah123.\n",
            "Note: This script is configured to run on your local device.\n",
            "\n",
            "Opening rumah123 search page...\n",
            "\n",
            "Note: A Stop button window will appear. Click it to stop scraping and save data.\n",
            "\n",
            "Starting local Chrome driver...\n",
            "Driver started successfully.\n",
            "Opening page 104: https://www.rumah123.com/jual/dki-jakarta/tanah/?page=104\n",
            "Waiting for page layout to settle before scrolling...\n",
            "Starting scroll (slower and deeper)...\n",
            "-- Scrolling... (1), waiting for content...\n",
            "-- Page height not changing, likely at bottom.\n",
            "Doing one final scroll to the absolute bottom...\n",
            "Waiting 3 seconds at the bottom for final loads...\n",
            "Experiment: Scrolling back to top slowly...\n",
            "Experiment: Scrolling to middle (349px) and pausing...\n",
            "Scrolling finished for this page.\n",
            "Found 0 property links on page 104.\n",
            "No valid listings found on page 104. Stopping.\n",
            "Scraping completed (or stopped). Data saved to 'scraped_land_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import threading\n",
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "\n",
        "# --- Pesan Perkenalan ---\n",
        "print(\"Research by @Reza Anggoro\")\n",
        "print(\"Property @scraping V1.2\")\n",
        "print(\"Use it for Educational Purposes only!\")\n",
        "print(\"\\nThis script uses Chromium Browser to crawl data from Rumah123.\")\n",
        "print(\"Note: This script is configured to run on your local device.\")\n",
        "print(\"\\nOpening rumah123 search page...\\n\")\n",
        "print(\"Note: A Stop button window will appear. Click it to stop scraping and save data.\\n\")\n",
        "\n",
        "# --- Pengaturan Opsi Chrome untuk LOCAL (NON-HEADLESS) ---\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"start-maximized\")  # Membuka browser fullscreen\n",
        "#driver.set_page_load_timeout(60)\n",
        "# --- Menambahkan User Agent Acak ---\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
        "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36'\n",
        "]\n",
        "options.add_argument(f'user-agent={random.choice(user_agents)}')\n",
        "\n",
        "# --- Inisialisasi Driver Chrome ---\n",
        "print(\"Starting local Chrome driver...\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "print(\"Driver started successfully.\")\n",
        "\n",
        "# List untuk menyimpan data hasil scrape\n",
        "data_list = []\n",
        "\n",
        "# Path file CSV\n",
        "csv_file = './scraped_land_data.csv'\n",
        "\n",
        "# --- Pengecekan File CSV yang Sudah Ada ---\n",
        "if os.path.exists(csv_file):\n",
        "    old_file = csv_file.replace('.csv', '.old.csv')\n",
        "    try:\n",
        "        os.rename(csv_file, old_file)\n",
        "        print(f\"Found existing file {csv_file}, renaming to {old_file}\")\n",
        "    except OSError as e:\n",
        "        print(f\"Could not rename file {csv_file}. It might be open. Error: {e}\")\n",
        "        print(\"Exiting to prevent data loss.\")\n",
        "        driver.quit()\n",
        "        exit()\n",
        "\n",
        "# URL dasar\n",
        "base_url = \"https://www.rumah123.com/jual/dki-jakarta/tanah/?page=\"\n",
        "\n",
        "# Rentang halaman yang akan di-scrape\n",
        "start_page = 101\n",
        "end_page = 750\n",
        "\n",
        "# Flag untuk stop scraping\n",
        "stop_scraping = False\n",
        "\n",
        "# Fungsi untuk window tombol stop (jalan di thread terpisah)\n",
        "def stop_button_window():\n",
        "    global stop_scraping\n",
        "    root = tk.Tk()\n",
        "    root.title(\"Scraping Control\")\n",
        "    root.geometry(\"200x100\")\n",
        "\n",
        "    def on_stop():\n",
        "        global stop_scraping\n",
        "        stop_scraping = True\n",
        "        messagebox.showinfo(\"Stop\", \"Scraping will stop after current operation.\")\n",
        "        root.destroy()\n",
        "\n",
        "    button = tk.Button(root, text=\"Stop Scraping\", command=on_stop)\n",
        "    button.pack(pady=20)\n",
        "    root.mainloop()\n",
        "\n",
        "# Jalankan window stop di thread background\n",
        "threading.Thread(target=stop_button_window, daemon=True).start()\n",
        "\n",
        "# --- Loop Halaman Utama (PAGINATION) ---\n",
        "for page in range(start_page, end_page + 1):\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    url = base_url + str(page)\n",
        "    print(f\"Opening page {page}: {url}\")\n",
        "    driver.get(url)\n",
        "\n",
        "    # Jeda acak untuk memuat halaman\n",
        "    time.sleep(random.uniform(3, 6))\n",
        "\n",
        "    # --- Pengecekan CAPTCHA yang Terlihat ---\n",
        "    captcha_detected = False\n",
        "    try:\n",
        "        captcha_element = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "        if captcha_element.is_displayed():\n",
        "            captcha_detected = True\n",
        "    except NoSuchElementException:\n",
        "        pass\n",
        "\n",
        "    if captcha_detected:\n",
        "        print(f\"!!! CAPTCHA DETECTED on page {page}. !!!\")\n",
        "        print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\n",
        "        print(\"!!! Skrip akan menjeda selama 25 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "        time.sleep(25)\n",
        "        print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "    # --- Blok untuk Scrolling ---\n",
        "    print(\"Waiting for page layout to settle before scrolling...\")\n",
        "    time.sleep(1.5)\n",
        "\n",
        "    total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    current_scroll = 0\n",
        "    scroll_count = 1\n",
        "    max_scroll_attempts = 50\n",
        "    print(\"Starting scroll (slower and deeper)...\")\n",
        "\n",
        "    while current_scroll < total_height and scroll_count < max_scroll_attempts:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        scroll_amount = random.randint(400, 700)\n",
        "        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
        "\n",
        "        print(f\"-- Scrolling... ({scroll_count}), waiting for content...\")\n",
        "        time.sleep(random.uniform(1.5, 2.2))\n",
        "\n",
        "        current_scroll += scroll_amount\n",
        "        scroll_count += 1\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "        if new_height == total_height:\n",
        "            print(\"-- Page height not changing, likely at bottom.\")\n",
        "            break\n",
        "        total_height = new_height\n",
        "\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    print(\"Doing one final scroll to the absolute bottom...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "    print(\"Waiting 3 seconds at the bottom for final loads...\")\n",
        "    time.sleep(3.0)\n",
        "\n",
        "    print(\"Experiment: Scrolling back to top slowly...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
        "    time.sleep(random.uniform(1.5, 2.5))\n",
        "\n",
        "    mid_height = total_height // 2\n",
        "    print(f\"Experiment: Scrolling to middle ({mid_height}px) and pausing...\")\n",
        "    driver.execute_script(f\"window.scrollTo(0, {mid_height});\")\n",
        "    time.sleep(random.uniform(2.0, 3.0))\n",
        "\n",
        "    print(\"Scrolling finished for this page.\")\n",
        "\n",
        "    # --- Ambil semua link (href) dari halaman daftar ---\n",
        "    href_list = []\n",
        "    try:\n",
        "        listings = driver.find_elements(By.CSS_SELECTOR, \"a.gap-1.w-full\")\n",
        "        for listing in listings:\n",
        "            try:\n",
        "                href = listing.get_attribute('href')\n",
        "                if href and href.startswith('https://www.rumah123.com/properti/'):\n",
        "                    href_list.append(href)\n",
        "            except:\n",
        "                pass\n",
        "        href_list = list(dict.fromkeys(href_list))\n",
        "        print(f\"Found {len(href_list)} property links on page {page}.\")\n",
        "    except NoSuchElementException:\n",
        "        print(f\"No more listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    if not href_list:\n",
        "        print(f\"No valid listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    # --- Loop Halaman Detail (per link) ---\n",
        "    for href in href_list:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Opening detail page: {href}\")\n",
        "\n",
        "        try:\n",
        "            # Coba buka halaman\n",
        "            driver.get(href)\n",
        "\n",
        "        except TimeoutException:\n",
        "            # Jika halaman gagal dimuat dalam 60 detik\n",
        "            print(f\"!!! PAGE TIMEOUT: Halaman {href} terlalu lama dimuat. Melewati...\")\n",
        "            # 'continue' akan mengabaikan sisa kode di loop ini\n",
        "            # dan langsung lanjut ke 'href' berikutnya\n",
        "            continue\n",
        "\n",
        "        except Exception as e:\n",
        "            # Menangkap error lain jika terjadi\n",
        "            print(f\"!!! ERROR LAIN saat membuka {href}: {e}. Melewati...\")\n",
        "            continue\n",
        "\n",
        "        # Kode ini hanya akan berjalan JIKA 'driver.get()' BERHASIL\n",
        "        time.sleep(random.uniform(3, 6))\n",
        "        # ... (sisa kode Anda untuk cek CAPTCHA dan extract data) ...\n",
        "        # Cek VISIBLE CAPTCHA di halaman detail\n",
        "        captcha_detected = False\n",
        "        try:\n",
        "            captcha_element_detail = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "            if captcha_element_detail.is_displayed():\n",
        "                captcha_detected = True\n",
        "        except NoSuchElementException:\n",
        "            pass\n",
        "\n",
        "        if captcha_detected:\n",
        "            print(f\"!!! CAPTCHA DETECTED on detail page {href}. !!!\")\n",
        "            print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "            time.sleep(20)\n",
        "            print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "        # Tambahkan scroll sedikit pada page detail (2-3 kali)\n",
        "        detail_scroll_count = random.randint(2, 3)\n",
        "        for i in range(detail_scroll_count):\n",
        "            scroll_amount = random.randint(200, 400)\n",
        "            driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
        "            time.sleep(random.uniform(0.5, 1.0))\n",
        "\n",
        "        # Tambahkan waktu sedikit untuk memastikan seluruh nilai muncul\n",
        "        time.sleep(random.uniform(2, 3))\n",
        "\n",
        "        # Coba klik tombol \"Muat lebih banyak\" (jika ada)\n",
        "        expand_clicked = False\n",
        "        try:\n",
        "            expand_container = driver.find_element(By.CSS_SELECTOR, \"#property-information > div:nth-of-type(1) > div:nth-of-type(2)\")\n",
        "            expand_button = expand_container.find_element(By.CSS_SELECTOR, \"span[data-test-id='expanded-specification']\")\n",
        "            ActionChains(driver).move_to_element(expand_button).perform()\n",
        "            time.sleep(random.uniform(0.5, 1))\n",
        "            expand_button.click()\n",
        "            time.sleep(random.uniform(1, 2))\n",
        "            print(\"Successfully clicked 'Muat lebih banyak' button.\")\n",
        "            expand_clicked = True\n",
        "        except Exception as e:\n",
        "            print(f\"No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\")\n",
        "\n",
        "        # --- Blok Ekstraksi Data (DIPERBAIKI: Tambah try-except lengkap) ---\n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        while retry_count < max_retries:\n",
        "            data = {}\n",
        "            try:\n",
        "                data['Product_sku_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(4) p.text-sm\").text\n",
        "            except:\n",
        "                data['Product_sku_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Place_name_0'] = driver.find_element(By.TAG_NAME, \"h1\").text\n",
        "            except:\n",
        "                data['Place_name_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Total_Price_0'] = driver.find_element(By.CSS_SELECTOR, \"span.text-primary\").text\n",
        "            except:\n",
        "                data['Total_Price_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Price_per_meter_0'] = driver.find_element(By.CSS_SELECTOR, \"span.font-normal.text-sm\").text\n",
        "            except:\n",
        "                data['Price_per_meter_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Land_Area_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex-col:nth-of-type(1) p.text-gray-800\").text\n",
        "            except:\n",
        "                data['Land_Area_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Certificate_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.text-base\").text\n",
        "            except:\n",
        "                data['Certificate_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Land_Dimensions_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(1) p.font-medium.text-sm\").text\n",
        "            except:\n",
        "                data['Land_Dimensions_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Property_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.font-medium.text-sm\").text\n",
        "            except:\n",
        "                data['Property_Type_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Ad_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.items-center:nth-of-type(3) p.text-sm\").text\n",
        "            except:\n",
        "                data['Ad_Type_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Place_PostalAddress_addressLocality_0'] = driver.find_element(By.CSS_SELECTOR, \"p.mb-2\").text\n",
        "            except:\n",
        "                data['Place_PostalAddress_addressLocality_0'] = ''\n",
        "\n",
        "            try:\n",
        "                data['BreadcrumbList_ListItem_name_2'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(4) a\").text\n",
        "            except:\n",
        "                data['BreadcrumbList_ListItem_name_2'] = ''\n",
        "\n",
        "            try:\n",
        "                data['BreadcrumbList_ListItem_name_3'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(5) a\").text\n",
        "            except:\n",
        "                data['BreadcrumbList_ListItem_name_3'] = ''\n",
        "\n",
        "            try:\n",
        "                data['Product_description_0'] = driver.find_element(By.CSS_SELECTOR, \"p.font-light.text-sm\").text\n",
        "            except:\n",
        "                data['Product_description_0'] = ''\n",
        "\n",
        "            # Peningkatan 1: Cek jika CAPTCHA terdeteksi berdasarkan 'Place_name_0'\n",
        "            if data['Place_name_0'] == 'www.rumah123.com':\n",
        "                print(f\"!!! CAPTCHA DETECTED via data check on detail page {href}. !!!\")\n",
        "                print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\n",
        "                print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "                time.sleep(20)\n",
        "                print(\"Waktu jeda selesai, reloading detail page...\")\n",
        "                driver.get(href)\n",
        "                time.sleep(random.uniform(3, 6))\n",
        "                retry_count += 1\n",
        "                continue  # Ekstrak ulang\n",
        "            else:\n",
        "                break  # Sukses, lanjut\n",
        "\n",
        "        if retry_count == max_retries:\n",
        "            print(f\"Max retries reached for {href}. Proceeding with possibly incomplete data.\")\n",
        "\n",
        "        # Peningkatan 2: Koreksi inkonsistensi jika expand gagal\n",
        "        if not expand_clicked:\n",
        "            # Shift values based on observed mismatch\n",
        "            temp_sku = data['Ad_Type_0']\n",
        "            temp_ad_type = data['Property_Type_0']\n",
        "            temp_property_type = data['Land_Dimensions_0']\n",
        "            # Assume Land_Dimensions not available or parse from description if needed\n",
        "            data['Product_sku_0'] = temp_sku\n",
        "            data['Ad_Type_0'] = temp_ad_type\n",
        "            data['Property_Type_0'] = temp_property_type\n",
        "            data['Land_Dimensions_0'] = ''  # Or extract from description if possible\n",
        "\n",
        "        # Print data untuk debug\n",
        "        print(f\"Extracted data: {data}\")\n",
        "\n",
        "        data_list.append(data)\n",
        "\n",
        "        # Simpan data ke CSV secara bertahap\n",
        "        df = pd.DataFrame(data_list)\n",
        "        df.to_csv(csv_file, index=False)\n",
        "        print(f\"Your data saved to: {csv_file}\")\n",
        "        print(f\"Total items saved: {len(data_list)}\\n\")\n",
        "\n",
        "        # Jeda sebelum kembali ke halaman daftar\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Going back to listing page {page}...\")\n",
        "        driver.get(url)\n",
        "        time.sleep(random.uniform(2, 4))\n",
        "\n",
        "    # Jeda antar halaman\n",
        "    print(f\"--Finished page {page}. Taking a break, waiting for 10 seconds...\\n\")\n",
        "    time.sleep(10)\n",
        "\n",
        "# --- Selesai ---\n",
        "driver.quit()\n",
        "\n",
        "# Simpan data terakhir jika belum\n",
        "if data_list:\n",
        "    df = pd.DataFrame(data_list)\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"Final data saved to: {csv_file}\")\n",
        "    print(f\"Total items saved: {len(data_list)}\")\n",
        "\n",
        "print(\"Scraping completed (or stopped). Data saved to 'scraped_land_data.csv'.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq0LoQKKe7F9",
        "outputId": "1692c742-093a-4f19-b407-96ff1db8fec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research by @Reza Anggoro\n",
            "Property @scraping V1.2\n",
            "Use it for Educational Purposes only!\n",
            "\n",
            "This script uses Chromium Browser to crawl data from Rumah123.\n",
            "Note: This script is configured to run on your local device.\n",
            "\n",
            "Opening rumah123 search page...\n",
            "\n",
            "Note: A Stop button window will appear. Click it to stop scraping and save data.\n",
            "\n",
            "Starting local Chrome driver...\n",
            "Driver started successfully.\n",
            "Opening page 101: https://www.rumah123.com/jual/dki-jakarta/tanah/?page=101\n",
            "Waiting for page layout to settle before scrolling...\n",
            "Starting scroll (slower and deeper)...\n",
            "-- Scrolling... (1), waiting for content...\n",
            "-- Scrolling... (2), waiting for content...\n",
            "-- Page height not changing, likely at bottom.\n",
            "Doing one final scroll to the absolute bottom...\n",
            "Waiting 3 seconds at the bottom for final loads...\n",
            "Experiment: Scrolling back to top slowly...\n",
            "Experiment: Scrolling to middle (9659px) and pausing...\n",
            "Scrolling finished for this page.\n",
            "Found 15 property links on page 101.\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-selatan-tanjung-barat/tanah-kavling-di-rancho-tb-simatupang-jakarta-selatan-shm-las3556723/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'Dijual', 'Place_name_0': 'Tanah kavling di Rancho TB Simatupang jakarta selatan SHM', 'Total_Price_0': 'Rp 25 Miliar Total', 'Price_per_meter_0': 'Rp 10 Juta /m²', 'Land_Area_0': '2500 m²', 'Certificate_0': 'SHM', 'Land_Dimensions_0': '', 'Property_Type_0': 'Ada', 'Ad_Type_0': 'Tanah', 'Place_PostalAddress_addressLocality_0': 'Tanjung Barat, Jakarta Selatan', 'BreadcrumbList_ListItem_name_2': 'Jakarta Selatan', 'BreadcrumbList_ListItem_name_3': 'Tanjung Barat', 'Product_description_0': 'DIJUAL TANAH KAVLING\\nDi Jalan Tanjung, TB Simatupang, Jakarta Selatan\\nCocok banget untuk dibuat mini cluster.\\nSekitaran sudah banyak cluster2 dan town house. \\nDekat dengan Rancho\\n\\nLuas 2.500 m2\\nHarga murah, 10jt/m masih nego\\nSHM\\n\\nMore Info : \\nLena Gading Pro GS\\n08138011xxxx'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 1\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-barat-cengkareng/tanah-komersil-dibawah-njop-di-cengkareng-jakarta-barat-las3642309/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'Dijual', 'Place_name_0': 'Tanah komersil dibawah NJOP di Cengkareng jakarta barat', 'Total_Price_0': 'Rp 215 Miliar Total', 'Price_per_meter_0': 'Rp 13 Juta /m²', 'Land_Area_0': '16600 m²', 'Certificate_0': 'HGB', 'Land_Dimensions_0': '', 'Property_Type_0': 'Ada', 'Ad_Type_0': 'Tanah', 'Place_PostalAddress_addressLocality_0': 'Cengkareng, Jakarta Barat', 'BreadcrumbList_ListItem_name_2': 'Jakarta Barat', 'BreadcrumbList_ListItem_name_3': 'Cengkareng', 'Product_description_0': 'Dijual Kavling Tanah dibawah NJOP\\nPinggir Jalan Raya Utama\\nCengkareng Jakarta Barat\\n● Luas tanah 16.600 m2\\n● Lebar muka 80 meter\\n● Zona Ungu (Commercial sd 24 lantai)\\n● SHGB \\n● Tanah Padat\\n● Lokasi 500m ke polsek Cengkareng, dekat ke Bandara\\n● Harga dibawah NJOP 13jt/m\\n\\nLena Gading Pro GS\\n08138011xxxx'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 2\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-utara-pantai-indah-kapuk/kavling-pik-pinisi-permai-418m2-lokasi-bagus-las8967703/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'las8967703', 'Place_name_0': 'Kavling Pik Pinisi Permai 418m2, Lokasi Bagus', 'Total_Price_0': 'Rp 12,5 Miliar Total', 'Price_per_meter_0': 'Rp 30 Juta /m²', 'Land_Area_0': '418 m²', 'Certificate_0': 'PPJB', 'Land_Dimensions_0': '', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Pantai Indah Kapuk, Jakarta Utara', 'BreadcrumbList_ListItem_name_2': 'Jakarta Utara', 'BreadcrumbList_ListItem_name_3': 'Pantai Indah Kapuk', 'Product_description_0': 'Dijual cepat\\nKavling / tanah Pik\\nPinisi Permai\\nLuas 418m\\nbadan\\nhadap Utara\\nHarga 30jt/m\\nNego\\n\\nInfo dan survey\\nVivie Ma - Infinite Estate\\n08778271xxxx'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 3\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-barat-palmerah/dijual-kavling-siap-bangun-di-jl-aster-jati-pulo-palmerah-las3719039/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'las3719039', 'Place_name_0': 'Dijual Kavling Siap Bangun di Jl Aster Jati Pulo Palmerah', 'Total_Price_0': 'Rp 3,8 Miliar Total', 'Price_per_meter_0': '', 'Land_Area_0': '180 m²', 'Certificate_0': 'SHM', 'Land_Dimensions_0': '', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Palmerah, Jakarta Barat', 'BreadcrumbList_ListItem_name_2': 'Jakarta Barat', 'BreadcrumbList_ListItem_name_3': 'Palmerah', 'Product_description_0': 'Di jual kavling siap bangun bentuk kotak Luas tanah 180 SHM Harga 3.9 M nego\\n\\nJl. Aster\\n\\nRW.1, Jati Pulo, Palmerah, West Jakarta City'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 4\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-barat-meruya/dijual-tanah-luas-bonus-3-bangunan-rumah-di-maruya-las3691352/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'las3691352', 'Place_name_0': 'Dijual Tanah Luas Bonus 3 Bangunan Rumah di Maruya', 'Total_Price_0': 'Rp 19 Miliar Total', 'Price_per_meter_0': '', 'Land_Area_0': '400 m²', 'Certificate_0': 'Lainnya', 'Land_Dimensions_0': '', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Meruya, Jakarta Barat', 'BreadcrumbList_ListItem_name_2': 'Jakarta Barat', 'BreadcrumbList_ListItem_name_3': 'Meruya', 'Product_description_0': 'Dijual tanah luas bonus 3 bangunan rumah di Maruya jalan H.\\n\\nAja meruya Jakarta barat.'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 5\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-timur-jakarta-garden-city/dijual-kavling-luas-18x165m-di-cluster-lantana-jgc-las4354953/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'Dijual', 'Place_name_0': 'Dijual Kavling Luas 18x16,5m di Cluster Lantana JGC', 'Total_Price_0': 'Rp 3,1 Miliar Total', 'Price_per_meter_0': '', 'Land_Area_0': '297 m² (16x17m)', 'Certificate_0': 'Lainnya', 'Land_Dimensions_0': '', 'Property_Type_0': '16x17 m', 'Ad_Type_0': 'Tanah', 'Place_PostalAddress_addressLocality_0': 'Jakarta Garden City, Jakarta Timur', 'BreadcrumbList_ListItem_name_2': 'Jakarta Timur', 'BreadcrumbList_ListItem_name_3': 'Jakarta Garden City', 'Product_description_0': 'Dijual Kavling Luas 18x16,5m di Cluster Lantana JGC \\n\\nKAVLING CLUSTER LANTANA JGC, Cakung, Cakung Timur, Jakarta Timur\\nLT/LB : 297/0 (18x16,5)\\nHadap : Barat\\n\\nCluster. Dekat Sekolah. Dekat Rumah Sakit. Dekat Jalan Raya. Dekat Mall. Pusat Kuliner. Pasar. Pusat Bisnis. Dekat Toll. Dekat SPBU. Dekat Bank. Dekat Tempat Ibadah. \\nPPJB\\n\\nHARGA : Rp. 3.100.000.xxx\\n\\nSURVEY SEKARANG HUBUNGI :\\nMeli Nyoo\\nMAX PROPERTI\\n08789698xxxx\\nRIT024'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 6\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-timur-cipayung/tanah-shm-2-kavling-50-dan-160-siap-bangun-las8950223/\n",
            "Successfully clicked 'Muat lebih banyak' button.\n",
            "Extracted data: {'Product_sku_0': 'las8950223', 'Place_name_0': 'Tanah Shm 2 Kavling 50 Dan 160 Siap Bangun', 'Total_Price_0': 'Rp 185 Juta Total', 'Price_per_meter_0': 'Rp 3,7 Juta /m²', 'Land_Area_0': '50 m² (10x5m)', 'Certificate_0': 'SHM', 'Land_Dimensions_0': '10x5 m', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Cipayung, Jakarta Timur', 'BreadcrumbList_ListItem_name_2': 'Jakarta Timur', 'BreadcrumbList_ListItem_name_3': 'Cipayung', 'Product_description_0': 'Tanah Dijual MURAH di Cilangkap Jakarta\\nTimur\\nDetail:\\nLegalitas SHM \\nShm 1 luas 50 meter \\nShm 2 luas 160 meter\\n\\nTanah padat tidak tanah ngurug\\nSiap bangun\\nAkses jalan masuk mobil \\nDekat dengan pintu toll cibubur \\n\\nHarga 3,7jt/m '}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 7\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-barat-puri-indah/kavling-hook-murah-di-puri-kembangan-jakarta-barat-las3483170/\n",
            "Successfully clicked 'Muat lebih banyak' button.\n",
            "Extracted data: {'Product_sku_0': 'las3483170', 'Place_name_0': 'Kavling hook murah di puri kembangan jakarta barat', 'Total_Price_0': 'Rp 4,92 Miliar Total', 'Price_per_meter_0': 'Rp 22 Juta /m²', 'Land_Area_0': '224 m² (15x15m)', 'Certificate_0': 'HGB', 'Land_Dimensions_0': '15x15 m', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Puri Indah, Jakarta Barat', 'BreadcrumbList_ListItem_name_2': 'Jakarta Barat', 'BreadcrumbList_ListItem_name_3': 'Puri Indah', 'Product_description_0': 'Jual cepat Kavling Hook \\ndi Puri Media, Kembangan\\nJakarta Barat\\nLokasi bagus tdk jauh dari gerbang komplek\\nDepan taman\\nLuas 224 m2\\nHGB\\nHadap Barat dan Utara\\nHarga 22jt/m\\n\\nLena gading pro\\n08138011xxxx'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 8\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-barat-puri-indah/kavling-hook-puri-media-hadap-barat-utara-sudah-sertifikat-las8893116/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'las8893116', 'Place_name_0': 'Kavling Hook Puri Media Hadap Barat Utara Sudah Sertifikat', 'Total_Price_0': 'Rp 4,92 Miliar Total', 'Price_per_meter_0': 'Rp 22 Juta /m²', 'Land_Area_0': '224 m²', 'Certificate_0': 'HGB', 'Land_Dimensions_0': '', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Puri Indah, Jakarta Barat', 'BreadcrumbList_ListItem_name_2': 'Jakarta Barat', 'BreadcrumbList_ListItem_name_3': 'Puri Indah', 'Product_description_0': 'DIJUAL Murah, Dibawah harga Pasaran\\nKavling Hook\\n*Puri Media* Kembangan\\nJakarta Barat\\n\\n》Lokasi bagus tdk jauh dari gerbang komplek\\n》Depan taman\\n》Luas 224 m2 (15x15)\\n》HGB sd 2054, Bisa KPT\\n》Hadap Barat dan Utara\\n》Harga 22jt/m\\n\\nLena Gadingpro GS\\n08138011xxxx'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 9\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-pusat-pasar-baru/tanah-dibawah-njop-pasar-baru-jakarta-pusat-las8950456/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'las8950456', 'Place_name_0': 'Tanah dibawah NJOP Pasar Baru Jakarta Pusat', 'Total_Price_0': 'Rp 3,2 Miliar Total', 'Price_per_meter_0': '', 'Land_Area_0': '212 m²', 'Certificate_0': 'HGB', 'Land_Dimensions_0': '', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Pasar Baru, Jakarta Pusat', 'BreadcrumbList_ListItem_name_2': 'Jakarta Pusat', 'BreadcrumbList_ListItem_name_3': 'Pasar Baru', 'Product_description_0': 'Tanah dibawah NJOP Pasar Baru Jakarta Pusat\\n\\nDijual tanah di JALAN LAUTZE\\nJAKARTA PUSAT\\n \\nLuas Tanah = 212m²\\n\\nLokasi PREMIUM\\nPinggir Jalan Raya\\nRow 2 Mobil\\nSertifikat HGB \\n\\nHarga NJOP = 5.9 M\\n\\nHarga JUAL = 3.2Miliar\\n\\n\\nKur.gp.al'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 10\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-timur-duren-sawit/murah-tanah-kavling-murah-kehakiman-duren-sawit-las8951567/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'las8951567', 'Place_name_0': 'Murah Tanah Kavling Kehakiman Duren Sawit', 'Total_Price_0': 'Rp 5,19 Miliar Total', 'Price_per_meter_0': 'Rp 9,8 Juta /m²', 'Land_Area_0': '530 m²', 'Certificate_0': 'SHM', 'Land_Dimensions_0': '', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Duren Sawit, Jakarta Timur', 'BreadcrumbList_ListItem_name_2': 'Jakarta Timur', 'BreadcrumbList_ListItem_name_3': 'Duren Sawit', 'Product_description_0': 'MURAHH Kavling Kehakiman\\nDuren Sawit Jakarta Timur\\nSertifikat : SHM\\nLuas : 530\\nHarga 9,8jt/meter negoo\\n\\nrayh.pan'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 11\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-utara-cilincing/tanah-murah-strategis-siap-bangun-di-jl-cilincing-raya-las2932846/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'Dijual', 'Place_name_0': 'Tanah Murah Strategis siap Bangun di jl Cilincing Raya', 'Total_Price_0': 'Rp 32,7 Miliar Total', 'Price_per_meter_0': '', 'Land_Area_0': '10225 m² (204x50m)', 'Certificate_0': 'SHM', 'Land_Dimensions_0': '', 'Property_Type_0': '204x50 m', 'Ad_Type_0': 'Tanah', 'Place_PostalAddress_addressLocality_0': 'Cilincing, Jakarta Utara', 'BreadcrumbList_ListItem_name_2': 'Jakarta Utara', 'BreadcrumbList_ListItem_name_3': 'Cilincing', 'Product_description_0': 'Tanah Luas Pinggir SUPER STRATEGIS\\nJalan Raya di jl Cilincing Raya Tarumajaya dekat Pintu toll Cibitung Cilincing \\n\\nCOCOK UNTUK PERUNTUKAN \\n\\n-Cluster/Perumahan\\n-Area Komersil \\n-Pergudangan\\n-Pabrik\\n-Sekolah atau Kampus\\n-Mall\\n-Rumah sakit \\n-Logistick\\n-DLL\\n\\nLuas Tanah : 10.225 meter \\nLebar : 50 m\\nPanjang : 204 m\\n\\nHarga 2.950.000 / meter (nego) BU\\n\\nAkses jalan lebar 3 mobil \\n\\nLokasi Terbaik :\\n1 KM dr Gerbang Toll Cibitung Cilincing\\nDekat Marunda Center\\nDekat Fasilitas lingkungan sekitar Segara City\\nDekat RS Tarumajaya\\n\\nPokoknya Mak nyos pingir jalan utama'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 12\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-utara-marunda/tanah-luas-pingir-jalan-propinsi-jl-cilincing-raya-tarumajaya-bekasi-las2714770/\n",
            "Successfully clicked 'Muat lebih banyak' button.\n",
            "Extracted data: {'Product_sku_0': 'Dijual', 'Place_name_0': 'Tanah Luas Pingir Jalan Propinsi Jl Cilincing Raya Tarumajaya Bekasi', 'Total_Price_0': 'Rp 32 Juta Total', 'Price_per_meter_0': 'Rp 3,2 Juta /m²', 'Land_Area_0': '10 m² (44x220m)', 'Certificate_0': 'SHM', 'Land_Dimensions_0': '44x220 m', 'Property_Type_0': 'Ada', 'Ad_Type_0': 'Tanah', 'Place_PostalAddress_addressLocality_0': 'Marunda, Jakarta Utara', 'BreadcrumbList_ListItem_name_2': 'Jakarta Utara', 'BreadcrumbList_ListItem_name_3': 'Marunda', 'Product_description_0': 'Tanah Luas Pinggir SUPER STRATEGIS BU \\nJalan Raya di jl Cilincing Raya Tarumajaya dekat Pintu toll Cibitung Cilincing \\n\\nCOCOK UNTUK PERUNTUKAN \\n-Cluster/Perumahan\\n-Area Komersil \\n-Pergudangan\\n-Pabrik\\n-Sekolah atau Kampus\\n-Mall\\n-Rumah sakit \\n-Logistick\\n-DLL\\n\\nLuas Tanah : 10.225 meter \\nLebar : 45 m\\nPanjang : 204 m\\n\\nAkses jalan lebar 3 mobil \\nLokasi Terbaik :\\n\\n1 KM dr Gerbang Toll Cibitung Cilincing\\nDekat pelabuhan\\nDekat Marunda Center\\nDekat Fasilitas lingkungan sekitar Segara City\\nDekat RS Tarumajaya\\n\\nPokoknya Mak nyos pingir jalan utama \\nNEGO SAMPAI JADI'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 13\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-timur-cibubur/dijual-tanah-di-cibubur-jakarta-timur-dekat-cibubur-junction-las8982784/\n",
            "No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\n",
            "Extracted data: {'Product_sku_0': 'las8982784', 'Place_name_0': 'Dijual Tanah di Cibubur Jakarta Timur dekat Cibubur Junction', 'Total_Price_0': 'Rp 3,95 Miliar Total', 'Price_per_meter_0': '', 'Land_Area_0': '439 m²', 'Certificate_0': 'Lainnya', 'Land_Dimensions_0': '', 'Property_Type_0': 'Tanah', 'Ad_Type_0': 'Dijual', 'Place_PostalAddress_addressLocality_0': 'Cibubur, Jakarta Timur', 'BreadcrumbList_ListItem_name_2': 'Jakarta Timur', 'BreadcrumbList_ListItem_name_3': 'Cibubur', 'Product_description_0': 'Dijual Tanah di Cibubur Jakarta Timur dekat Cibubur Junction\\nLokasi strategis, pinggir jalan ramai, potensial untuk tempat usaha, \\n\\nLuas Tanah: 439 m2\\nLuas Bangunan: 0 m2\\nKamar Tidur: 0\\nKamar Mandi: 0\\n\\nRp3.950.000.xxx nego\\n\\nPosisi 2 km dari pintu tol Jagorawi. \\nCocok untuk tempat usaha. Pinggir jalan langsung.\\nLingkungan padat penduduk dan perumahan. \\nBebas banjir, belum pernah banjir 1x pun juga selama puluhan tahun.\\nDekat dengan sekolah, rumah sakit, masjid, mall Cibubur junction, bengkel, dll. \\nLingkungan lama, sudah sangat ramai. \\nAkses strategis ke berbagai tujuan jalur utama\\n\\nHubungi \\nIrene \\n+628191xxxxxxx\\nGP Alsut'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 14\n",
            "\n",
            "Going back to listing page 101...\n",
            "Opening detail page: https://www.rumah123.com/properti/jakarta-barat-palmerah/jual-cepat-tanah-komersial-di-palmerah-barat-jakarta-pusat-las4141407/\n",
            "Successfully clicked 'Muat lebih banyak' button.\n",
            "Extracted data: {'Product_sku_0': 'Dijual', 'Place_name_0': 'Disewakan / Jual Cepat Tanah Komersial Di Palmerah Barat Jakarta Pusat', 'Total_Price_0': 'Rp 83,1 Miliar Total', 'Price_per_meter_0': 'Rp 24 Juta /m²', 'Land_Area_0': '3465 m² (24x147m)', 'Certificate_0': 'HGB', 'Land_Dimensions_0': '24x147 m', 'Property_Type_0': 'Ada', 'Ad_Type_0': 'Tanah', 'Place_PostalAddress_addressLocality_0': 'Palmerah, Jakarta Barat', 'BreadcrumbList_ListItem_name_2': 'Jakarta Barat', 'BreadcrumbList_ListItem_name_3': 'Palmerah', 'Product_description_0': 'Disewakan / Dijual cepat tanah  di jl Palmerah Barat jakarta pusat\\n- Disewakan ruangan ex resto padang sederhana, jl palmerah barat\\nharga sewa rp 350,000,000 / th\\nluas 20 x 15 ( 300 m2 )\\nready Januari 2026.\\nDijual :\\nBisa untuk komersial, untuk Rumah Sakit, showroom mobil/motor, resto dll. \\nDiatas tanah ada bangunan tua ex pabrik batik yang saat ini masih disewa di bagian belakang untuk lapangan footsal\\nSemua hitung tanah\\nLT 3465 m2 ( 23,5 x 147 ) \\nLB 2306\\nListrik 33000 watt\\nIMB\\nBentuk tanah ngantong\\nSertifikat HGB sampai 8 Mei  2040\\nHarga turun dari rp 27 jt /m2 jadi rp 24 jt/m2 \\nNote : serius buyer bisa nego sampai deal . \\nMore info : \\nastuti gading pro pik\\nHP 08389070xxxx'}\n",
            "Your data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 15\n",
            "\n",
            "Going back to listing page 101...\n",
            "--Finished page 101. Taking a break, waiting for 10 seconds...\n",
            "\n",
            "Opening page 102: https://www.rumah123.com/jual/dki-jakarta/tanah/?page=102\n",
            "Waiting for page layout to settle before scrolling...\n",
            "Starting scroll (slower and deeper)...\n",
            "-- Scrolling... (1), waiting for content...\n",
            "-- Page height not changing, likely at bottom.\n",
            "Doing one final scroll to the absolute bottom...\n",
            "Waiting 3 seconds at the bottom for final loads...\n",
            "Experiment: Scrolling back to top slowly...\n",
            "Experiment: Scrolling to middle (349px) and pausing...\n",
            "Scrolling finished for this page.\n",
            "Found 0 property links on page 102.\n",
            "No valid listings found on page 102. Stopping.\n",
            "Final data saved to: ./scraped_land_data.csv\n",
            "Total items saved: 15\n",
            "Scraping completed (or stopped). Data saved to 'scraped_land_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OLD Version V1"
      ],
      "metadata": {
        "id": "Q447HQLe6dZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob3nRz7kkoep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6e79e5-eeb2-4800-d442-3f2879a93336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom selenium import webdriver\\nfrom selenium.webdriver.common.by import By\\nfrom selenium.webdriver.common.action_chains import ActionChains\\nfrom selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\\nimport time\\nimport random\\nimport pandas as pd\\nimport os\\nimport threading\\nimport tkinter as tk\\nfrom tkinter import messagebox\\n\\n# --- Pesan Perkenalan ---\\nprint(\"Research by @Reza Anggoro\")\\nprint(\"Property @scraping V1.0\")\\nprint(\"Use it for Educational Purposes only!\")\\nprint(\"\\nThis script uses Chromium Browser to crawl data from Rumah123.\")\\nprint(\"Note: This script is configured to run on your local device.\")\\nprint(\"\\nOpening rumah123 search page...\\n\")\\nprint(\"Note: A Stop button window will appear. Click it to stop scraping and save data.\\n\")\\n\\n# --- Pengaturan Opsi Chrome untuk LOCAL (NON-HEADLESS) ---\\noptions = webdriver.ChromeOptions()\\noptions.add_argument(\"start-maximized\")  # Membuka browser fullscreen\\n\\n# --- Menambahkan User Agent Acak ---\\nuser_agents = [\\n    \\'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\\',\\n    \\'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\\',\\n    \\'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36\\'\\n]\\noptions.add_argument(f\\'user-agent={random.choice(user_agents)}\\')\\n\\n# --- Inisialisasi Driver Chrome ---\\nprint(\"Starting local Chrome driver...\")\\ndriver = webdriver.Chrome(options=options)\\nprint(\"Driver started successfully.\")\\n\\n# List untuk menyimpan data hasil scrape\\ndata_list = []\\n\\n# Path file CSV\\ncsv_file = \\'./scraped_land_data.csv\\'\\n\\n# --- Pengecekan File CSV yang Sudah Ada ---\\nif os.path.exists(csv_file):\\n    old_file = csv_file.replace(\\'.csv\\', \\'.old.csv\\')\\n    try:\\n        os.rename(csv_file, old_file)\\n        print(f\"Found existing file {csv_file}, renaming to {old_file}\")\\n    except OSError as e:\\n        print(f\"Could not rename file {csv_file}. It might be open. Error: {e}\")\\n        print(\"Exiting to prevent data loss.\")\\n        driver.quit()\\n        exit()\\n\\n# URL dasar\\nbase_url = \"https://www.rumah123.com/jual/dki-jakarta/tanah/?page=\"\\n\\n# Rentang halaman yang akan di-scrape\\nstart_page = 81\\nend_page = 120\\n\\n# Flag untuk stop scraping\\nstop_scraping = False\\n\\n# Fungsi untuk window tombol stop (jalan di thread terpisah)\\ndef stop_button_window():\\n    global stop_scraping\\n    root = tk.Tk()\\n    root.title(\"Scraping Control\")\\n    root.geometry(\"200x100\")\\n\\n    def on_stop():\\n        global stop_scraping\\n        stop_scraping = True\\n        messagebox.showinfo(\"Stop\", \"Scraping will stop after current operation.\")\\n        root.destroy()\\n\\n    button = tk.Button(root, text=\"Stop Scraping\", command=on_stop)\\n    button.pack(pady=20)\\n    root.mainloop()\\n\\n# Jalankan window stop di thread background\\nthreading.Thread(target=stop_button_window, daemon=True).start()\\n\\n# --- Loop Halaman Utama (PAGINATION) ---\\nfor page in range(start_page, end_page + 1):\\n    if stop_scraping:\\n        break\\n\\n    url = base_url + str(page)\\n    print(f\"Opening page {page}: {url}\")\\n    driver.get(url)\\n\\n    # Jeda acak untuk memuat halaman\\n    time.sleep(random.uniform(3, 6))\\n\\n    # --- Pengecekan CAPTCHA yang Terlihat ---\\n    captcha_detected = False\\n    try:\\n        captcha_element = driver.find_element(By.CSS_SELECTOR, \\'iframe[src*=\"recaptcha\"], div.g-recaptcha\\')\\n        if captcha_element.is_displayed():\\n            captcha_detected = True\\n    except NoSuchElementException:\\n        pass\\n\\n    if captcha_detected:\\n        print(f\"!!! CAPTCHA DETECTED on page {page}. !!!\")\\n        print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\\n        print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\\n        time.sleep(20)\\n        print(\"Waktu jeda selesai, melanjutkan skrip...\")\\n\\n    # --- Blok untuk Scrolling ---\\n    print(\"Waiting for page layout to settle before scrolling...\")\\n    time.sleep(1.5)\\n\\n    total_height = driver.execute_script(\"return document.body.scrollHeight\")\\n    current_scroll = 0\\n    scroll_count = 1\\n    max_scroll_attempts = 50\\n    print(\"Starting scroll (slower and deeper)...\")\\n\\n    while current_scroll < total_height and scroll_count < max_scroll_attempts:\\n        if stop_scraping:\\n            break\\n\\n        scroll_amount = random.randint(400, 700)\\n        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\\n\\n        print(f\"-- Scrolling... ({scroll_count}), waiting for content...\")\\n        time.sleep(random.uniform(1.5, 2.2))\\n\\n        current_scroll += scroll_amount\\n        scroll_count += 1\\n\\n        new_height = driver.execute_script(\"return document.body.scrollHeight\")\\n\\n        if new_height == total_height:\\n            print(\"-- Page height not changing, likely at bottom.\")\\n            break\\n        total_height = new_height\\n\\n    if stop_scraping:\\n        break\\n\\n    print(\"Doing one final scroll to the absolute bottom...\")\\n    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\\n\\n    print(\"Waiting 3 seconds at the bottom for final loads...\")\\n    time.sleep(3.0)\\n\\n    print(\"Experiment: Scrolling back to top slowly...\")\\n    driver.execute_script(\"window.scrollTo(0, 0);\")\\n    time.sleep(random.uniform(1.5, 2.5))\\n\\n    mid_height = total_height // 2\\n    print(f\"Experiment: Scrolling to middle ({mid_height}px) and pausing...\")\\n    driver.execute_script(f\"window.scrollTo(0, {mid_height});\")\\n    time.sleep(random.uniform(2.0, 3.0))\\n\\n    print(\"Scrolling finished for this page.\")\\n\\n    # --- Ambil semua link (href) dari halaman daftar ---\\n    href_list = []\\n    try:\\n        listings = driver.find_elements(By.CSS_SELECTOR, \"a.gap-1.w-full\")\\n        for listing in listings:\\n            try:\\n                href = listing.get_attribute(\\'href\\')\\n                if href and href.startswith(\\'https://www.rumah123.com/properti/\\'):\\n                    href_list.append(href)\\n            except:\\n                pass\\n        href_list = list(dict.fromkeys(href_list))\\n        print(f\"Found {len(href_list)} property links on page {page}.\")\\n    except NoSuchElementException:\\n        print(f\"No more listings found on page {page}. Stopping.\")\\n        break\\n\\n    if not href_list:\\n        print(f\"No valid listings found on page {page}. Stopping.\")\\n        break\\n\\n    # --- Loop Halaman Detail (per link) ---\\n    for href in href_list:\\n        if stop_scraping:\\n            break\\n\\n        time.sleep(random.uniform(1, 3))\\n        print(f\"Opening detail page: {href}\")\\n        driver.get(href)\\n        time.sleep(random.uniform(3, 6))\\n\\n        # Cek VISIBLE CAPTCHA di halaman detail\\n        captcha_detected = False\\n        try:\\n            captcha_element_detail = driver.find_element(By.CSS_SELECTOR, \\'iframe[src*=\"recaptcha\"], div.g-recaptcha\\')\\n            if captcha_element_detail.is_displayed():\\n                captcha_detected = True\\n        except NoSuchElementException:\\n            pass\\n\\n        if captcha_detected:\\n            print(f\"!!! CAPTCHA DETECTED on detail page {href}. !!!\")\\n            print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\\n            time.sleep(20)\\n            print(\"Waktu jeda selesai, melanjutkan skrip...\")\\n\\n        # Coba klik tombol \"Muat lebih banyak\" (jika ada)\\n        try:\\n            expand_container = driver.find_element(By.CSS_SELECTOR, \"#property-information > div:nth-of-type(1) > div:nth-of-type(2)\")\\n            expand_button = expand_container.find_element(By.CSS_SELECTOR, \"span[data-test-id=\\'expanded-specification\\']\")\\n            ActionChains(driver).move_to_element(expand_button).perform()\\n            time.sleep(random.uniform(0.5, 1))\\n            expand_button.click()\\n            time.sleep(random.uniform(1, 2))\\n            print(\"Successfully clicked \\'Muat lebih banyak\\' button.\")\\n        except Exception as e:\\n            print(f\"No \\'Muat lebih banyak\\' button found or click failed. Proceeding without expansion.\")\\n\\n        # --- Blok Ekstraksi Data (DIPERBAIKI: Tambah try-except lengkap) ---\\n        data = {}\\n        try:\\n            data[\\'Product_sku_0\\'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(4) p.text-sm\").text\\n        except:\\n            data[\\'Product_sku_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Place_name_0\\'] = driver.find_element(By.TAG_NAME, \"h1\").text\\n        except:\\n            data[\\'Place_name_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Total_Price_0\\'] = driver.find_element(By.CSS_SELECTOR, \"span.text-primary\").text\\n        except:\\n            data[\\'Total_Price_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Price_per_meter_0\\'] = driver.find_element(By.CSS_SELECTOR, \"span.font-normal.text-sm\").text\\n        except:\\n            data[\\'Price_per_meter_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Land_Area_0\\'] = driver.find_element(By.CSS_SELECTOR, \"div.flex-col:nth-of-type(1) p.text-gray-800\").text\\n        except:\\n            data[\\'Land_Area_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Certificate_0\\'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.text-base\").text\\n        except:\\n            data[\\'Certificate_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Land_Dimensions_0\\'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(1) p.font-medium.text-sm\").text\\n        except:\\n            data[\\'Land_Dimensions_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Property_Type_0\\'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.font-medium.text-sm\").text\\n        except:\\n            data[\\'Property_Type_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Ad_Type_0\\'] = driver.find_element(By.CSS_SELECTOR, \"div.items-center:nth-of-type(3) p.text-sm\").text\\n        except:\\n            data[\\'Ad_Type_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Place_PostalAddress_addressLocality_0\\'] = driver.find_element(By.CSS_SELECTOR, \"p.mb-2\").text\\n        except:\\n            data[\\'Place_PostalAddress_addressLocality_0\\'] = \\'\\'\\n\\n        try:\\n            data[\\'BreadcrumbList_ListItem_name_2\\'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(4) a\").text\\n        except:\\n            data[\\'BreadcrumbList_ListItem_name_2\\'] = \\'\\'\\n\\n        try:\\n            data[\\'BreadcrumbList_ListItem_name_3\\'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(5) a\").text\\n        except:\\n            data[\\'BreadcrumbList_ListItem_name_3\\'] = \\'\\'\\n\\n        try:\\n            data[\\'Product_description_0\\'] = driver.find_element(By.CSS_SELECTOR, \"p.font-light.text-sm\").text\\n        except:\\n            data[\\'Product_description_0\\'] = \\'\\'\\n\\n        # Print data untuk debug\\n        print(f\"Extracted data: {data}\")\\n\\n        data_list.append(data)\\n\\n        # Simpan data ke CSV secara bertahap\\n        df = pd.DataFrame(data_list)\\n        df.to_csv(csv_file, index=False)\\n        print(f\"Your data saved to: {csv_file}\")\\n        print(f\"Total items saved: {len(data_list)}\\n\")\\n\\n        # Jeda sebelum kembali ke halaman daftar\\n        time.sleep(random.uniform(1, 3))\\n        print(f\"Going back to listing page {page}...\")\\n        driver.get(url)\\n        time.sleep(random.uniform(2, 4))\\n\\n    # Jeda antar halaman\\n    print(f\"--Finished page {page}. Taking a break, waiting for 10 seconds...\\n\")\\n    time.sleep(10)\\n\\n# --- Selesai ---\\ndriver.quit()\\n\\n# Simpan data terakhir jika belum\\nif data_list:\\n    df = pd.DataFrame(data_list)\\n    df.to_csv(csv_file, index=False)\\n    print(f\"Final data saved to: {csv_file}\")\\n    print(f\"Total items saved: {len(data_list)}\")\\n\\nprint(\"Scraping completed (or stopped). Data saved to \\'scraped_land_data.csv\\'.\")\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\"\"\"\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import threading\n",
        "import tkinter as tk\n",
        "from tkinter import messagebox\n",
        "\n",
        "# --- Pesan Perkenalan ---\n",
        "print(\"Research by @Reza Anggoro\")\n",
        "print(\"Property @scraping V1.0\")\n",
        "print(\"Use it for Educational Purposes only!\")\n",
        "print(\"\\nThis script uses Chromium Browser to crawl data from Rumah123.\")\n",
        "print(\"Note: This script is configured to run on your local device.\")\n",
        "print(\"\\nOpening rumah123 search page...\\n\")\n",
        "print(\"Note: A Stop button window will appear. Click it to stop scraping and save data.\\n\")\n",
        "\n",
        "# --- Pengaturan Opsi Chrome untuk LOCAL (NON-HEADLESS) ---\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"start-maximized\")  # Membuka browser fullscreen\n",
        "\n",
        "# --- Menambahkan User Agent Acak ---\n",
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
        "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36'\n",
        "]\n",
        "options.add_argument(f'user-agent={random.choice(user_agents)}')\n",
        "\n",
        "# --- Inisialisasi Driver Chrome ---\n",
        "print(\"Starting local Chrome driver...\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "print(\"Driver started successfully.\")\n",
        "\n",
        "# List untuk menyimpan data hasil scrape\n",
        "data_list = []\n",
        "\n",
        "# Path file CSV\n",
        "csv_file = './scraped_land_data.csv'\n",
        "\n",
        "# --- Pengecekan File CSV yang Sudah Ada ---\n",
        "if os.path.exists(csv_file):\n",
        "    old_file = csv_file.replace('.csv', '.old.csv')\n",
        "    try:\n",
        "        os.rename(csv_file, old_file)\n",
        "        print(f\"Found existing file {csv_file}, renaming to {old_file}\")\n",
        "    except OSError as e:\n",
        "        print(f\"Could not rename file {csv_file}. It might be open. Error: {e}\")\n",
        "        print(\"Exiting to prevent data loss.\")\n",
        "        driver.quit()\n",
        "        exit()\n",
        "\n",
        "# URL dasar\n",
        "base_url = \"https://www.rumah123.com/jual/dki-jakarta/tanah/?page=\"\n",
        "\n",
        "# Rentang halaman yang akan di-scrape\n",
        "start_page = 81\n",
        "end_page = 120\n",
        "\n",
        "# Flag untuk stop scraping\n",
        "stop_scraping = False\n",
        "\n",
        "# Fungsi untuk window tombol stop (jalan di thread terpisah)\n",
        "def stop_button_window():\n",
        "    global stop_scraping\n",
        "    root = tk.Tk()\n",
        "    root.title(\"Scraping Control\")\n",
        "    root.geometry(\"200x100\")\n",
        "\n",
        "    def on_stop():\n",
        "        global stop_scraping\n",
        "        stop_scraping = True\n",
        "        messagebox.showinfo(\"Stop\", \"Scraping will stop after current operation.\")\n",
        "        root.destroy()\n",
        "\n",
        "    button = tk.Button(root, text=\"Stop Scraping\", command=on_stop)\n",
        "    button.pack(pady=20)\n",
        "    root.mainloop()\n",
        "\n",
        "# Jalankan window stop di thread background\n",
        "threading.Thread(target=stop_button_window, daemon=True).start()\n",
        "\n",
        "# --- Loop Halaman Utama (PAGINATION) ---\n",
        "for page in range(start_page, end_page + 1):\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    url = base_url + str(page)\n",
        "    print(f\"Opening page {page}: {url}\")\n",
        "    driver.get(url)\n",
        "\n",
        "    # Jeda acak untuk memuat halaman\n",
        "    time.sleep(random.uniform(3, 6))\n",
        "\n",
        "    # --- Pengecekan CAPTCHA yang Terlihat ---\n",
        "    captcha_detected = False\n",
        "    try:\n",
        "        captcha_element = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "        if captcha_element.is_displayed():\n",
        "            captcha_detected = True\n",
        "    except NoSuchElementException:\n",
        "        pass\n",
        "\n",
        "    if captcha_detected:\n",
        "        print(f\"!!! CAPTCHA DETECTED on page {page}. !!!\")\n",
        "        print(\"!!! ANDA HARUS MENYELESAIKANNYA DI JENDELA BROWSER SEKARANG. !!!\")\n",
        "        print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "        time.sleep(20)\n",
        "        print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "    # --- Blok untuk Scrolling ---\n",
        "    print(\"Waiting for page layout to settle before scrolling...\")\n",
        "    time.sleep(1.5)\n",
        "\n",
        "    total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    current_scroll = 0\n",
        "    scroll_count = 1\n",
        "    max_scroll_attempts = 50\n",
        "    print(\"Starting scroll (slower and deeper)...\")\n",
        "\n",
        "    while current_scroll < total_height and scroll_count < max_scroll_attempts:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        scroll_amount = random.randint(400, 700)\n",
        "        driver.execute_script(f\"window.scrollBy(0, {scroll_amount});\")\n",
        "\n",
        "        print(f\"-- Scrolling... ({scroll_count}), waiting for content...\")\n",
        "        time.sleep(random.uniform(1.5, 2.2))\n",
        "\n",
        "        current_scroll += scroll_amount\n",
        "        scroll_count += 1\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "        if new_height == total_height:\n",
        "            print(\"-- Page height not changing, likely at bottom.\")\n",
        "            break\n",
        "        total_height = new_height\n",
        "\n",
        "    if stop_scraping:\n",
        "        break\n",
        "\n",
        "    print(\"Doing one final scroll to the absolute bottom...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "    print(\"Waiting 3 seconds at the bottom for final loads...\")\n",
        "    time.sleep(3.0)\n",
        "\n",
        "    print(\"Experiment: Scrolling back to top slowly...\")\n",
        "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
        "    time.sleep(random.uniform(1.5, 2.5))\n",
        "\n",
        "    mid_height = total_height // 2\n",
        "    print(f\"Experiment: Scrolling to middle ({mid_height}px) and pausing...\")\n",
        "    driver.execute_script(f\"window.scrollTo(0, {mid_height});\")\n",
        "    time.sleep(random.uniform(2.0, 3.0))\n",
        "\n",
        "    print(\"Scrolling finished for this page.\")\n",
        "\n",
        "    # --- Ambil semua link (href) dari halaman daftar ---\n",
        "    href_list = []\n",
        "    try:\n",
        "        listings = driver.find_elements(By.CSS_SELECTOR, \"a.gap-1.w-full\")\n",
        "        for listing in listings:\n",
        "            try:\n",
        "                href = listing.get_attribute('href')\n",
        "                if href and href.startswith('https://www.rumah123.com/properti/'):\n",
        "                    href_list.append(href)\n",
        "            except:\n",
        "                pass\n",
        "        href_list = list(dict.fromkeys(href_list))\n",
        "        print(f\"Found {len(href_list)} property links on page {page}.\")\n",
        "    except NoSuchElementException:\n",
        "        print(f\"No more listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    if not href_list:\n",
        "        print(f\"No valid listings found on page {page}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    # --- Loop Halaman Detail (per link) ---\n",
        "    for href in href_list:\n",
        "        if stop_scraping:\n",
        "            break\n",
        "\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Opening detail page: {href}\")\n",
        "        driver.get(href)\n",
        "        time.sleep(random.uniform(3, 6))\n",
        "\n",
        "        # Cek VISIBLE CAPTCHA di halaman detail\n",
        "        captcha_detected = False\n",
        "        try:\n",
        "            captcha_element_detail = driver.find_element(By.CSS_SELECTOR, 'iframe[src*=\"recaptcha\"], div.g-recaptcha')\n",
        "            if captcha_element_detail.is_displayed():\n",
        "                captcha_detected = True\n",
        "        except NoSuchElementException:\n",
        "            pass\n",
        "\n",
        "        if captcha_detected:\n",
        "            print(f\"!!! CAPTCHA DETECTED on detail page {href}. !!!\")\n",
        "            print(\"!!! Skrip akan menjeda selama 20 DETIK agar Anda bisa menyelesaikannya. !!!\")\n",
        "            time.sleep(20)\n",
        "            print(\"Waktu jeda selesai, melanjutkan skrip...\")\n",
        "\n",
        "        # Coba klik tombol \"Muat lebih banyak\" (jika ada)\n",
        "        try:\n",
        "            expand_container = driver.find_element(By.CSS_SELECTOR, \"#property-information > div:nth-of-type(1) > div:nth-of-type(2)\")\n",
        "            expand_button = expand_container.find_element(By.CSS_SELECTOR, \"span[data-test-id='expanded-specification']\")\n",
        "            ActionChains(driver).move_to_element(expand_button).perform()\n",
        "            time.sleep(random.uniform(0.5, 1))\n",
        "            expand_button.click()\n",
        "            time.sleep(random.uniform(1, 2))\n",
        "            print(\"Successfully clicked 'Muat lebih banyak' button.\")\n",
        "        except Exception as e:\n",
        "            print(f\"No 'Muat lebih banyak' button found or click failed. Proceeding without expansion.\")\n",
        "\n",
        "        # --- Blok Ekstraksi Data (DIPERBAIKI: Tambah try-except lengkap) ---\n",
        "        data = {}\n",
        "        try:\n",
        "            data['Product_sku_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(4) p.text-sm\").text\n",
        "        except:\n",
        "            data['Product_sku_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Place_name_0'] = driver.find_element(By.TAG_NAME, \"h1\").text\n",
        "        except:\n",
        "            data['Place_name_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Total_Price_0'] = driver.find_element(By.CSS_SELECTOR, \"span.text-primary\").text\n",
        "        except:\n",
        "            data['Total_Price_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Price_per_meter_0'] = driver.find_element(By.CSS_SELECTOR, \"span.font-normal.text-sm\").text\n",
        "        except:\n",
        "            data['Price_per_meter_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Land_Area_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex-col:nth-of-type(1) p.text-gray-800\").text\n",
        "        except:\n",
        "            data['Land_Area_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Certificate_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.text-base\").text\n",
        "        except:\n",
        "            data['Certificate_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Land_Dimensions_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(1) p.font-medium.text-sm\").text\n",
        "        except:\n",
        "            data['Land_Dimensions_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Property_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.flex:nth-of-type(2) p.font-medium.text-sm\").text\n",
        "        except:\n",
        "            data['Property_Type_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Ad_Type_0'] = driver.find_element(By.CSS_SELECTOR, \"div.items-center:nth-of-type(3) p.text-sm\").text\n",
        "        except:\n",
        "            data['Ad_Type_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Place_PostalAddress_addressLocality_0'] = driver.find_element(By.CSS_SELECTOR, \"p.mb-2\").text\n",
        "        except:\n",
        "            data['Place_PostalAddress_addressLocality_0'] = ''\n",
        "\n",
        "        try:\n",
        "            data['BreadcrumbList_ListItem_name_2'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(4) a\").text\n",
        "        except:\n",
        "            data['BreadcrumbList_ListItem_name_2'] = ''\n",
        "\n",
        "        try:\n",
        "            data['BreadcrumbList_ListItem_name_3'] = driver.find_element(By.CSS_SELECTOR, \".flex div:nth-of-type(5) a\").text\n",
        "        except:\n",
        "            data['BreadcrumbList_ListItem_name_3'] = ''\n",
        "\n",
        "        try:\n",
        "            data['Product_description_0'] = driver.find_element(By.CSS_SELECTOR, \"p.font-light.text-sm\").text\n",
        "        except:\n",
        "            data['Product_description_0'] = ''\n",
        "\n",
        "        # Print data untuk debug\n",
        "        print(f\"Extracted data: {data}\")\n",
        "\n",
        "        data_list.append(data)\n",
        "\n",
        "        # Simpan data ke CSV secara bertahap\n",
        "        df = pd.DataFrame(data_list)\n",
        "        df.to_csv(csv_file, index=False)\n",
        "        print(f\"Your data saved to: {csv_file}\")\n",
        "        print(f\"Total items saved: {len(data_list)}\\n\")\n",
        "\n",
        "        # Jeda sebelum kembali ke halaman daftar\n",
        "        time.sleep(random.uniform(1, 3))\n",
        "        print(f\"Going back to listing page {page}...\")\n",
        "        driver.get(url)\n",
        "        time.sleep(random.uniform(2, 4))\n",
        "\n",
        "    # Jeda antar halaman\n",
        "    print(f\"--Finished page {page}. Taking a break, waiting for 10 seconds...\\n\")\n",
        "    time.sleep(10)\n",
        "\n",
        "# --- Selesai ---\n",
        "driver.quit()\n",
        "\n",
        "# Simpan data terakhir jika belum\n",
        "if data_list:\n",
        "    df = pd.DataFrame(data_list)\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"Final data saved to: {csv_file}\")\n",
        "    print(f\"Total items saved: {len(data_list)}\")\n",
        "\n",
        "print(\"Scraping completed (or stopped). Data saved to 'scraped_land_data.csv'.\")\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAGcbr0tzTrztuo5mHXp6J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}